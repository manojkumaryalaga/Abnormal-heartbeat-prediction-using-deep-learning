Abstract—Cardiovascular diseases are increasing day by daydue to an increase in unhealthy lifestyles. Cardiovasculardiseases require prompt action and automatic abnormal beatdetection can improve promptness by many folds. Earlydetection of abnormal heartbeats is crucial fortimelyintervention and improved patient outcomes. This studypresents a Convolutional Neural Network (CNN) approach fortheautomaticdiscovery of normal, abnormal heartbeats usingtheMIT-BIH Arrhythmia dataset for validation. Dataset,renowned for its diverse range of arrhythmias, provides acomprehensive testbed for training and evaluating the proposedCNN model.Designs and solutions to be proposedPreprocessing techniques are employed toquote relevanttypes from electrocardiogram indications, a CNN architectureis designed to learn discriminative patterns associated withnormal and abnormal heartbeats.Half of theMIT-BIH sampleis used forthetraining model, while theother half is used toassess its performance. It achieves an F1-score of 96%, anaccuracy of 97%, a precision of 97%,anda recall of 95%.Summary of conclusion to be drawnThese results demonstrate CNN's ability to accuratelydistinguish between normal andabnormalheartbeats,showcasing its potential as a robusttool for automatedarrhythmia detection. This research contributes to the ongoingefforts to develop efficient and reliable systems for earlydetection of cardiovascular irregularities, thereby facilitatingtimely medical interventions.Keywords—abnormal beat detection, deep neural network,convoluted neural network, signalprocessing.I. INTRODUCTIONA. Overview of Abnormal Heartbeat DetectionIn recent years, artificial intelligence (AI) has usheredin a paradigm shift in automation, endowing machines withthe capability to intelligently detect and predict outcomes.This transformative technology has found compellingapplications intheground of biomedical signal processing,chiefly inthedomain of cardiovascular disease (CVD)detection. CVD is one oftheforemost reasons of death in theworld [1].It ismostly predominant in low, middle-incomenations. So automatic beat detection aims to offload theburden of medical experts for false alarms, on one hand,while alerting unaware patients about their cardiac health onthe other. The most popular signal analyzed for evaluatingcardiac health is electrocardiogram (ECG). ECG signalsundergo both long-term and short-term evaluations for theidentification of different cardiac conditions. Long-termECG analysis is typically employed for detecting arrhythmias.However, lasting ECG analysis is atiresome,time-consumingprocess,disposed to humanmistakes, which can have a direimpact when swift disease detection and intervention are ofextreme importance. Hence abnormal beat detection is donefor the ease of patients, caregivers as welland medicalexperts.B. Research Problem To be StudiedThe primary research problem is the reliable detectionof abnormal beats in ECG signals, aiming to alleviate theburden on medical experts and provide timely alerts topatients regarding their cardiac health. The challenge lies inachieving high accuracy and efficiency in abnormal beatdetection, especially for rare types of cardiovasculardiseases (CVDs).C. Motivation Behind the ProblemThe motivation behind the research is the pressing needto enhance cardiac health analysis by automating the detectionof abnormal beats. Traditional methods, including long-termECG analysis, are tedious and prone to errors. The motivationis to leverage advanced technologies, such as deep learning, toimprove the accuracy and speed of abnormal beat detection,ultimately contributing to timely disease intervention.D. Existing Methods to Solve the ProblemAbnormal beat detection has been an active area ofresearch for the past 30 years. Automatic cardiac healthanalysis [2], [3] is a popularresearch area. For the detectionof diseases, the most common workflow is preprocessing,followedbyfeatureextractionandclassification.Preprocessing mainly includes signal quality assessment anddenoising. This is followed by beat segmentation forpreprocessing and further analysis is usually done on a beatwise basis.In this time of 30 long years of research for automaticdetection, performance has improved by implementingdifferent types of advanced feature extraction and machinelearning tools. Feature extractions like morphologicalfeatures [4], DWT-basedfeatures [5], ICA features [6], orlikewise are used. This is usually followed by machinelearning toolslikeSVM [7], decision tree [8] and k-NN [9].With the advancement of deep learning, different architectures[10] are applied for highly improved detection with anaccuracy of more than 95%. For further extending theresearch, there is an urgent need to emphasize the need for robust methodologies that can reliably detect rare types of cardiovascular diseases (CVDs) in futureexploration.E. Proposed MethodThe proposed method involves detecting abnormalbeats using a deep neural network (CNN). ECG signals arepreprocessed and segmented into individual beats for beatwise analysis. The CNN model automatically extracts featuresfrom the data, contributing to the accurate prediction of normaland abnormal beats. A comparison is made with a plain deepneural network (DNN), and the output is a regression valueserving as the decision threshold. The methodology isvalidatedusingtheMIT-BIHArrhythmiadatabase,demonstrating accurate abnormal beat detection.In this work, abnormal beats are detected from normalbeats with the help of a deep neural network. Initially, ECG ispreprocessed and segmented into individual beats. The analysisis done beat by beat. Thus, each beat is given as a contributionto the CNN model for the prediction of normal and abnormalbeats. CNN model automatically mines features according todata. In this work, a CNN is used as a deep learning manner fordetection. For ablation, CNN is associated with a plain deepneural network (DNN). Output is the regression value which isthe threshold for obtaining the decision. This methodologyshows an accurate detection of abnormal beats detection fromone of the benchmark datasets MIT- BIH Arrhythmia database[11].In summary, the research focuses on leveragingadvanced technologies, particularly deep learning throughCNN, to address the research problem of accurate and efficientabnormal beat detection in ECG signals, motivated by thelimitations of existing methods and the critical importance oftimely cardiovascular disease detection.extraction, but the advent of deep learning [16], [17] hasintroduced novel and highly successful deep architectures. Deepneural networks, such as Convolutional Neural Networks(CNNs), have demonstrated their efficacy by achievingaccuracies exceeding 95% in detecting various cardiovasculardiseases (CVD). One key advantage of employing deep neuralnetworks is their automatic feature extraction capability. CNNs,for instance, can identify hidden patterns within signals,autonomously adjusting network weights and biases. Thisautomatic feature extraction enables the discovery of non-linearfeatures that enhance beat detection performance significantly.The application of deep learning in abnormal beat detection holdsgreat promise, providing a robust foundation for futuredevelopments to support medical personnel effectively. • Existing Non deep learning Methods used for detecting theabnormal heart beatMachine Learning algorithms like Support vector machines areused where they separate the data into groups, for example the 2data categories like abnormal heart rhythm and normal heartrhythm, from raw data images containing information ofheartbeats with the help of the straight line equation also calledhyperplane , Random Forests where the hierarchical nodes aredisplayed classifying the groups of the data, logistic regressionthat is nearly same as SVMs but it separate data into groupsusing exponential line equation instead of linear line equation.Data science techniques likeKNN where the data is separatedinto different categories based on the distance metricscalculated each group of data images representing samecharacteristic of behavior or pattern that are used for detectionofabnormal heart rhythm. Also feature extraction methods likestatistical methods and image processing methods displaygraphical representation of the data by finding the text andshape of the particular part of the image.wavelet transform is other technique used for parallellycalculating the repetition of the similar data along with the timeinterval. hardware components like sensors are also used fordetecting the abnormalities in the heart rhythm.II. RELATED WORKS▪ Existing Deep Learning Algorithms Usedfor Abnormal BeatDetection▪ Introduction to Automatic Abnormal Beat DetectionAutomatic abnormal beat detection is becoming increasingly essential in the field of cardiac health monitoring. Extensive research has been conducted to develop effective methods for this purpose. The typical workflow involves ECG preprocessing, followed by various types of feature extraction. Some approaches include feature selection before the actual detection process. As arrhythmia monitoring often occurs over extended periods and in ambulatory conditions, acquired ECG data is prone to noise, including muscle noise, baseline wander, and power line intrusion. To mitigate these influences on features, noise reduction techniques, such as Discrete Wavelet Transform (DWT) and Empirical Mode Decomposition (EMD), are commonly employed [12]. Once denoised, ECG signals are segmented into individual beats, and subsequent analysis is conducted on a beat-wise basis, providing detection results accordingly.▪ Integration of Deep Learning in Abnormal Beat DetectionAfter ECG preprocessing, the focus shifts to featureextraction, particularly in the realm of morphological features.This often involves the delineation of ECG beats, with specificattention to the detection of QRS complexes and delineationpoints [15]. Traditional methods have been prevalent in featureSeveral studies have leveraged neural networks for thedetection of abnormal beats, showcasing the significance ofConvolutional Neural Networks (CNNs) as both featureextractors and detectors. In literature [18], [17], [19], individualECGbeats are fed into CNNs to identify abnormal beats,highlighting the versatility of CNNs in this context. Differentvariations of CNN architectures have been implemented foreffective abnormal beat detection. For instance, [20] employs aconvolutional recurrent neural network (CRNN) to identifyvarious types of abnormal beats, while [21] combines CNN withlong short-term memory (LSTM). Other works, such as [22] and[29], utilize multitier deep learning models, and some integrateadditionalfeatureextractiontechniqueslikePrincipalComponent Analysis (PCA) with CNN. The diversity inapproaches demonstrates the adaptability of neural networks inaddressing the complexities of abnormal beat detection.▪ Fusion of Deep Learning Techniques for ImprovedPerformanceIn the pursuit of enhancing detection performance, researchers have explored combinations of deep learning techniques. In [23], a deep multi-scale combination CNN with spatio-temporal attention is employed for detection, offering a nuanced approach. Conversely, [24] combines twodirectional and two-dimensional Principal Component Analysis (PCA) with CNN for improved performance. Autoencoders combined with CNNs are explored in [25], while [26] focuses on feature extraction using an LSTMbased autoencoder (AE) network. Extracted features are then fed into a support vector machine (SVM) along with a duallevel attentional deep neural network [27]. Overall, deep learning has proven to enhance detection performance by projecting features into a more separable domain, allowing the extraction of finer discriminative features crucial for accurate abnormal beat discrimination.III. MethodologyIn this work, for the detection of abnormal beats the implementation of CNN, and DNN is done in Electrocardiogram (ECG) signals. The primary objective is to enhance the accuracy of abnormal beat classification by incorporating preprocessing techniques to address numerous categories of noise present in ECG signals. For this process, ECG signals are first denoised followed by R- peakdetection. The denoised data is split based on R-R interval into ECG beats. The ECG beats are given as input to CNN. Features are extracted by striding of filters chosen. The extracted features are given as input to an artificial neural network. All this is taken care of by CNN. The output is obtained as a regression value. This regression value is the threshold and is assigned to either abnormal or normal beats. The workflow is presented in below Fig.1A. ECG denoisingIn thepre-processing phase, theECG signal is denoisedby using a notch filter and DWT followed by hard thresholding.A notch filter is used to eliminate power-line intervention in thefrequencies 50 Hz and 60 Hz.After the removal of these twofrequency components from the noisy signal, the signal isdenoised with the help of spectrum 0-130 Hz approximately outof which only 0-70 Hz spectrum is useful. Thus, the R peak liesin the frequency range of 15-25Hz, whereas theP wave, andTwave lie in thefrequency range of 2-3 Hz and 3-5 Hz respectively.On applying DWT to an ECG signal, the signal is decomposedinto details, and the approximate coefficient of a particularfrequency range can be obtained. The principle of denoising ECGsignal by DWT is removing the coefficients whose frequencyrange is vulnerable to noise without hampering the usefulfrequency components.The two most important noises other than the powerlineinterference, which is removed by the notch filter, are baselineinterference (0-0.5 Hz) and electromyogram noise (above 100Hz). ECG indication is decomposed by 9-levels with the help ofFig.2. Data distribution of training and testing data for normal, abnormal beats inMIT-BIHArrhythmia database.Daubechies 6 as mother wavelet to decay indication intofrequency ranges in which noisy spectrum and useful spectrumcan be separated. The signal under a vulnerable frequency rangeis eliminated by hard thresholding. After elimination, thedecomposed signal is reconstructed by IDWT.B. R- peakdetectionR-peaks, crucial indicators of heartbeats, are extractedfrom the ECG signal using a predefined database. Thisinformation is utilized to segment the beats for furtheranalysis. Thus, analgorithm is particularly robust in thepresence of noise and various types of interference commonlyfound in real-world ECG recordings. The workflow diagramand steps for R-peak detection are discussed below:Fig.1. Signal processing flow of abnormalheartbeat detectionBandpass FilteringDifferentiationSquaringIntegrationThresholdingR-Peak Identification1. 2. 3. 4. 5. 6. Bandpass filtering: The algorithm begins with abandpass filter which isolates frequencies typical ofQRS developments (approximately 0.5 Hz to 50 Hz).This step helps in reducing noise and enhancing theprominent features of the QRS complex.Differentiation: The filtered signal undergoes adifferentiation process to highlight the steep slope ofthe QRS compound. Differentiation highlights therapid change in amplitude, providing a distinctivesignature for QRS detection.Squaring: The squared signal is computed to enhancethe QRS complex even further. This operationamplifies the already emphasized QRS features.Integration: A moving-windowintegration is appliedto smooth the squared signal. Integration helps intransforming the sharp peaks of the QRS complex intomore identifiable structures.Thresholding: A dynamic threshold is determinedbased on the signal's baseline and noise level. Peaksexceeding this threshold are considered likely R-peaks.R-Peak Identification: R-peaks are identified at thehighest points of the QRS complexes that exceed theadaptive threshold.The Pan-Tompkins algorithm demonstrates robust performance across a range of ECG signal variations and noise levels. Its computational efficiency makes it appropriate for real-time ECG monitoring applications. The use of adaptive thresholds enhances the algorithm's adaptability to varying noise levels and baseline shifts.The algorithm's straightforward implementation contributes to its widespread adoption.C. Beat segmentation.The beats are extracted by dividing consecutive R-Rintervals into 1:2 ratios. Two units of RR interval are for theprevious beat and one unit of RR interval is for the next beat.This divides the ECG signal into segments containing exactlyone heartbeat. The division into 1:2 ratio signifies fewerexamples before R-peak andmore samples after R-peak. Thisis a conventional way to extract a full heartbeat.D. Detection by convolutional neural networkThere is a 50-50 split in the dataset betweentraining andtestingsets.Thisconfirmsabalancedrepresentation of abnormal and normal beats in both sets.As aloss function, binary cross-entropy is used to constructtheCNNmodel, which is optimized usingtheAdam algorithm with alearning rate of 0.001. Twenty epochs with thirty-two batchesmake up the training loop.CNN operation is done in two foldsforward and backward propagation. The key steps in forwardpropagation can be summarized as follows:1. Convolutional Layers: Convolutional layers convolvethe input data with learnable filters to capture localpatterns. By making the network non-linear, activationfunctions make it possible for it to learn intricatecorrelations. Max pooling layers down-sample spatialdimensions, retaining essential information.2. Flattening Layer:Arrays with just one dimension arecreated by flattening theoutput of convolutional andpooling layers.This prepares the data for input into thedense layers.3. Dense Layers: Dense layers process the flattened data tocapture global patterns and relationships. Learnableweights and biases are applied, and activation functionsintroduce non-linearity.4. Final Output:It is onthelast layer that the networkgenerates its output,representing predictions oractivations.Task specificity dictates output layeractivation function selection.(e.g., SoftMax forclassification).Forward propagation enables the CNN to extracthierarchical features and relationships within the input data,facilitating effective pattern recognition. This processtransforms raw input into meaningful representations,ultimately leading to the network's output. Each layer plays aspecificroleinfeatureextractionandabstraction,contributing to the model's aptitude to make preciseestimates.Backward propagation is a crucial step in the trainingprocess of neural networks, allowing the model to learn fromits mistakes and optimize its parameters for improvedperformance. This iterative process involves the calculationof gradients to the loss function and the subsequentadjustment of weight and biases.1. Loss Calculation: The calculation of the loss, or thediscrepancy between the expected and actual targetvalues, is the first step in the backward propagationprocess. The task at hand determines which lossfunction to use, such as cross-entropy forclassification or mean squared error for regression.2. Gradient Computation: After that, gradients arecalculated concerning each model parameter(weights and biases). Calculating the impact of eachparameter change on the total loss involves using thecalculus chain rule.3. Backpropagation Through Layers: The computedgradients are then propagated backward through thelayers of the neural network. For each layer, thegradients are used to adjust the parameters in a way4. 5. that reduces the loss.Parameter Update: Based on the determinedgradients, the optimization procedure (such asgradient descent) is used to update the modelparameters. The number of steps made duringparameter updates is determined by the learningrate, which affects the convergence pace.Iterative Optimization: Backward propagation andparameter updates are performed iteratively overmultiple epochs. The model continues to learn fromthe training data, gradually improving its ability tomake accurate predictions.Backward propagation is essential for training neuralnetworks because it enables the model to adjust its internalparameters to diminish discrepancy among expected, actualconsequences. This procedure allows the network to learnintricate patterns, relationships, and representations within thedata.__________________________________________Algorithm 1: Training of CNN 1: Convolutional Layer 1: Filters (filter1), Activation Function (ReLU), Pooling (MaxPooling)2: Convolutional Layer 2: Filters (filter2), Activation Function (ReLU), Pooling (MaxPooling)3: Flatten Layer4: Dense Layer 1: Neurons (neurons1,ReLU)5: Dense Layer 2: Neurons (neurons2, Softmax)6: Load W and B from the pre-trained CNN model7: for each test_image in X_test:8: Conv1_output = Convolutional_Layer1(test_image)9: A1_output = ReLU(Conv1_output)10: P1_output = MaxPooling(Activation1_output)11: Conv2_output = Convolutional_Layer2 (P1_output)20. A2_output = ReLU(Conv2_output)21: P2_output = MaxPooling(A2_output)22: F_output = Flatten(P2_output)23: Dense1_o = ReLU(Dense_Layer1(F_output))24: O_scores = Softmax (Dense_Layer2 (Dense1_o))25: Predicted_class = argmax(O_scores)Input: Images (X), Corresponding Labels (Y)Hyperparameters: Learning Rate (alpha), Number of Epochs (num_epochs), Batch Size (batch_size)Output: weights and biases26: if Predicted_class>0.5:27: actual_class = 128: else:29: actual_class = 0 Thepictures of implementedmodels and the workflowdiagramsof the CNN and DNN models are show below1: Convolutional Layer 1← Filters (filter1), Activation Function (ReLU), Pooling (MaxPooling)2: Convolutional Layer 2 ←Filters (filter2), Activation Function (ReLU), Pooling (MaxPooling)3: Flatten Layer4: Dense Layer 1← Neurons (neurons1), Activation Function (ReLU)5: Dense Layer 2← Neurons (neurons2), Activation Function (Softmax)6: Randomly initialize weights and biases for each layer7: for epoch in (num_epochs):8: 9: shuffle and split data into batchesfor batch_data, batch_labels in batches: 10: Conv1_output = Convolutional_Layer1(batch_data)11: A1_output = ReLU(Conv1_output)12: P1_output = MaxPooling(A1_output)13: Conv2_output = Convolutional_Layer2 ( P1_output)14: A2_output = ReLU(Conv2_output)15: P2_output = MaxPooling(A2_output) 16: F_output = Flatten(P2_output)17: Dense1_output = ReLU(Dense_Layer1(F_output))18: =Softmax(Dense_Layer2(Dense1_output))O_scores 19: 20: loss = CrossEntropyLoss(O_scores, batch_labels)Compute Gradients using backpropagation21: Update Weights and Biases using gradient descent_________________________________________Algorithm 2: Prediction by CNN____________________________________________Input: Test ECG (X_test)Pre-trained CNN Model with Weights (W) and Biases (B)Output: actual class Backward pass involves. Similar convolutional and matrixoperations. The overall time complexity is similar(𝑁 ⋅ 𝐹 ⋅ 𝐻𝑜𝑢𝑡⋅ 𝑊𝑜𝑢𝑡 ⋅ 𝐶𝑖𝑛 ⋅ 𝐶𝑜𝑢𝑡)Space complexity for model parametersis.(𝑢𝑚_𝑝𝑎𝑟𝑎𝑚𝑎𝑡𝑒𝑟𝑠),where𝑛𝑢𝑚_𝑝𝑎𝑟𝑎𝑚𝑒𝑡𝑒𝑟𝑠 is the totalnumber of parameters (weights and biases) in the model. Theintermediate activation has a space complexity of(𝑁 ⋅ 𝐻𝑜𝑢𝑡 ⋅𝑊𝑜𝑢𝑡 ⋅ 𝐶𝑜𝑢𝑡),where𝑁 is the number of samples,𝐻𝑜𝑢𝑡 ×𝑊𝑜𝑢𝑡×𝐶𝑜𝑢𝑡 is the size of the output feature map.For batch training, the space complexity is(𝑏𝑎𝑡𝑐ℎ_𝑠𝑖𝑧𝑒 ⋅𝐻𝑖𝑛 ⋅ 𝑊𝑖𝑛 ⋅ 𝐶𝑖𝑛),where𝑏𝑎𝑡𝑐ℎ_𝑠𝑖𝑧𝑒 is the number of samples ina training batch,𝐻𝑖𝑛 ×𝑊𝑖𝑛 ×𝐶𝑖𝑛 is the size of the input featuremap. For batch testing space complexity is(𝑡𝑒𝑠𝑡_𝑏𝑎𝑡𝑐ℎ_𝑠𝑖𝑧𝑒 ⋅𝐻𝑖𝑛 ⋅ 𝑊𝑖𝑛 ⋅ 𝐶𝑖𝑛),𝑡𝑒𝑠𝑡_𝑏𝑎𝑡𝑐ℎ_𝑠𝑖𝑧𝑒 is the number of examples ina testing batch, and𝐻𝑖𝑛 ×𝑊𝑖𝑛 ×𝐶𝑖𝑛 is the size of the inputfeature map.F.Novelty of the MethodThenovelty of the work can be discussed in thesimplicity of the work. Though one aspect of abnormal beatdetection is accurate detection with the help of automatic Featureextraction by CNN that introduces non linearity for detectingaccurate heart beats, another aspect of the work is its latency. Asimple 2-layer CNN has performed very highly reliable detectionperformance. The execution is lightweight and hence morerelevant to practical problems of abnormal beat detection. AlsoCNN outputs the regression value used as threshold for theclassification of normal and abnormal heart beats soregressionvalueis another novel component of the method used for simplerclassification mechanism. Thus, an optimal architecture isdeveloped with high accuracy. Analysis has been provided in thework to prove this.The two models are taken to show how CNN modeloutperforms the DNN model in terms of classification metricslike precision and accuracy. Also CNN is more suitable fordetecting particular regional patterns and for similar sequentialdata as abnormal heart beat images varies only in particularpixels of data where DNN consider each image of as individualone. As in above CNN model with two convolution layers withdistinct size of filters like 5 and 3helps to get the patterns ofimages at different time spans and then pooling size 2 is takenfor reducing the image size and examining theimportantregional patterns in image where each image differs in thatlocal regions.CNN gives the regressive value for prediction. Henceto get the actual prediction the above and below the thresholdvalue is taken as two different classes.For ablation, a plain deep neural network isimplemented to show the importance of CNN over a plain deepneural network. CNN is made of two layers. The result has beendiscussed under the Result sections. For keeping parity withCNN, the DNN model is compiled using Adam optimizer withdefault parameters, and binary cross-entropy as a loss function.The training loop consists of 20 epochs with a batch size of 32.E.Time and space complexity of CNNThe time and space difficulty of training and testing aConvolutional Neural Network (CNN) depends on variousfactors, including the network architecture, the size of thedataset, and the hardware used for computation.For forward propagation, the time complexity is(𝑁 ⋅ 𝐹.𝐻𝑜𝑢𝑡 ⋅ 𝑊𝑜𝑢𝑡 ⋅ 𝐶𝑖𝑛 ⋅ 𝐶𝑜𝑢𝑡)where 𝑁 is the number of samples,𝐹 is filter size,𝐻𝑜𝑢𝑡, and𝑊𝑜𝑢𝑡 are output spatial dimensions,𝐶𝑖𝑛 is the number of input channels,𝐶𝑜𝑢𝑡 is number of outputchannels. This complexity arises from the convolutional layers.IV. RESULTS AND DISCUSSIONThis work aimsto detect abnormal beatsfromECG signalswith high accuracy. The detection of abnormal beats here isdone by initial pre-preprocessing which includes denoising, Rpeak detection, and segmentation. This is followed by featureextraction and classification. Both stages are taken care of by aconvolutional neural network (CNN).The whole evaluation isdone on theMIT-BIH Arrhythmia datasetas discussed earlier.In this section, the discussion will be done on the detectionperformance by CNN. To evaluate the importance of CNN thesame evaluation will be performed with a basic DNNstructure, and a comparison will be done between them. Thena comparison of results will be done between some of therecent works.1. Experimental setupThe execution is done in 12th Gen Intel(R) Core (TM)i5-1235U with 16GB RAM. The algorithms are executed inPython 3.9 in Jupiter Notebook.2. Algorithms under useFor ECG preprocessing the algorithmsused are DWTbased denoising and the Pan Tompkins algorithm for R-peakrecognition. For detection, the algorithms evaluated are CNN andDNN.3. Benchmark datasetIn this work, the MIT-BIH Arrhythmia database [11] isused for validation. 48 ECG recordings in this collection spanaround 30 minutes and were collected from 48 differentparticipants. Recordings have a resolution of 11 bits and asampling rate of 360 hertz. Out of 48 records, 23 records containcommonly occurring easy-to-detect abnormal beats, and theRemaining 25 recordings include a range of uncommon butclinically significant occurrencesthat can only be recorded overan extended period. For training and blind testing, the MIT-BIHArrhythmia dataset is split into 50-50. The data distribution isshown inbelow figureItcan be observed that the number of normal beats is less thanfive times the abnormal beat. Hence, according to the standardassumption, the data is balanced and does not introduce bias tothe classification model.4. Performance indicesAbnormal beat isdetected by CNN as discussed earlier.For evaluation of performance the following performancemetrics are evaluated:• Accuracy: The ratio of properly predicted instancesto total instances is used to compute it, and it is ameasure oftheoverall soundnessof the model.𝐶𝑜𝑟𝑟𝑒𝑐𝑡𝑙𝑦 𝑝𝑟𝑒𝑑𝑖𝑐𝑡𝑒𝑑 𝑜𝑢𝑡𝑝𝑢𝑡𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦 =_________________________________________𝑇𝑜𝑡𝑎𝑙 𝑛𝑢𝑚𝑏𝑒𝑟 𝑜𝑓 𝑝𝑟𝑒𝑑𝑖𝑐𝑡𝑖𝑜𝑛𝑠The CNN and DNN model loss decreasing for epochs indicatesthe algorithm is learning well and as a result,improving itsperformance where the model predicted values will become closeto the actual valuesfor epochs.400003500030000250002000015000100005000Normalbeat36548Abnormalbeat1292203654812925TrainTeDespite its simplicity, accuracy isn't always the bestmeasure to use when one class is grossly outnumbered in adataset. High accuracy might be deceiving ifa model is justprojecting the majority class in these instances.• Precision: Accuracy, or precision, is defined astheproportionofprojectedpositiveobservationsthatmaterialize. The precision of optimistic forecasts is themain emphasis.𝑇𝑟𝑢𝑒 𝑝𝑜𝑠𝑖𝑡𝑖𝑣𝑒Precision =_______________________________________𝑇𝑟𝑢𝑒 𝑝𝑜𝑠𝑖𝑡𝑖𝑣𝑒+𝐹𝑎𝑙𝑠𝑒 𝑝𝑜𝑠𝑖𝑡𝑖𝑣𝑒• Whentheprice of false positives is steep, accuracy becomesparamount. In the context of medical diagnosis, forinstance, a high degree of accuracy indicates that model isvery likely to be accurate when it predicts a favorableoutcome.• Recall (Sensitivity or True Positive Rate):Recall isaratio of correctly predicted positive observationsto total actual positives.It focuses on capturing all positiveinstances.𝑇𝑟𝑢𝑒 𝑝𝑜𝑠𝑖𝑡𝑖𝑣𝑒𝑅𝑒𝑐𝑎𝑙𝑙 = ______________________________𝑇𝑟𝑢𝑒 𝑝𝑜𝑠𝑖𝑡𝑖𝑣𝑒 +𝐹𝑎𝑙𝑠𝑒 𝑁𝑒𝑔𝑎𝑡𝑖𝑣𝑒With a hefty price tag for false negatives, recall becomesparamount. When it would be detrimental to overlook agood event, high recall is desirable. For instance, in spamemail detection, it's important not to miss any actual spam.• F1-Score:When recall and accuracy are harmonically averaged, theresult is the F1-score. By providing a single statistic that isboth balanced and accurate, it allows us to evaluate amodel's performance with ease.2 ×𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 ×𝑟𝑒𝑐𝑎𝑙𝑙𝐹1−𝑠𝑐𝑜𝑟𝑒 =____________________𝑝𝑟𝑒𝑐𝑠𝑖𝑖𝑜𝑛 +𝑟𝑒𝑐𝑎𝑙𝑙In cases of unequal class distribution,the F1 score provesto be particularly valuable. It is a good metric for binaryclassification problems, providing a trade-off betweenprecision and recall5. Classification performanceFor having a detailed insight on the classification performance confusion matrix is observed. When actual values of the input data are known, a classification model's performance may be described using a confusion matrix, a table used for this purpose. It is a useful tool for evaluating the performance of a classification algorithm and understanding where the model is making errors. The confusion matrix for the performance of the organization is shown in Table 1. The classification result provided by CNN is shown in Table 2. According to Table 1, there were 1,119 cases of normal beats being incorrectly identified as abnormal and 352 cases of abnormal beats being incorrectly classified as normal. This has led to an accuracy of 97%. Here we have discussed overall accuracy. The class-wise precision is 97% for normal and 99% for abnormal. The class-wise recall stands at 99% for normal and 91% for abnormal. The F1-score is 98% for normal and 94% for abnormal beats.TABLE I. CONFUSION MATRIC OF CLASSIFICATION BYCNNNormal AbnormalNormal 11806 1119Abnormal 352 36196TABLE II. CLASSIFICATION RESULT BY CNN ON MITDBThis would involve further improvement in CNNarchitecture which is bound to increase the memory andlatency requirement. However, with proper research, thedetection can be achieved in real-time. Forenhancedusability, this can be paired with IoT to send reports topatients as well as the concerned medical person for promptaction. Thus, this work forms the base of further explorationtoward thedetection of different types of abnormal beats thatoccur in a person inreal time.ClassAccuracy Classification metricsPrecision Recall F1-scoreREFERENCESNormal97 99 9897Abnormal 97 91 94From this, the detection issatisfactory and reliable fordetection.6. Ablation for CNN and DNN (Baseline Method)In this work for validation, the MIT-BIH ArrhythmiaDatabase (MITDB) is used for evaluation. It has 48 recordsfrom 48 dissimilar patients each of 30-minute duration. Thefull database is used for the evaluation of abnormal and normalbeats.As can be seen from Table 3 CNN has outperformedDNNby 5% in accuracy, 4% in recall, and 7% F1- score. By thisanalysis, it can be said that CNN can mine better features andclassifythem as compared to DNN.TABLE III. COMPARISON OF RESULTS BETWEEN CNN AND DNN[1] [2] [3] [4] S.Kaptogeetal.,“WorldHealthOrganizationcardiovascular disease risk charts: revised models toestimate risk in 21 global regions,” Lancet Glob. Heal., vol.7, no. 10, pp. e1332–e1345, 2019, doi:10.1016/S2214-109X(19)30318-3.X. Zhang, H. Wu, T. Chen, and G. Wang, “Automaticdiagnosis of arrhythmia with electrocardiogram usingmultiple instance learning: From rhythm annotation toheartbeat prediction,” Artif. Intell. Med., 2022, doi:10.1016/j.artmed.2022.102379.A. I. Kalyakulina et al., “LUDB: A new open-accessvalidationtoolforelectrocardiogramdelineationalgorithms,” IEEE Access, vol. 8, pp. 186181–186190,2020, doi: 10.1109/ACCESS.2020.3029211.Y. C. Yeh, W. J. Wang, and C. W.Chiou, “Cardiacarrhythmia diagnosis method using linear discriminantanalysis on ECG signals,” Meas. J. Int. Meas. Confed., vol.42, no. 5, 2009, doi: 10.1016/j.measurement.2009.01.004.Classification metricsClassAccuracy Precision Recall F1-scoreCNN 97 97 95 96DNN 92 97 91 897. Comparison with recent worksThe result produced by the discussedarchitecture of CNNhas produced aresult that is at par with other recent literature.This can be observed in Table IV.TABLE IV. COMPARISON OF RESULTS WITH RECENT LITERATURERef. Tool used Performance[28] MRFO- SVM Acc.: 97.83% , Se.: 97.87%, Spe :99.35%:, Pre : 97.68% , F-score:97.52%[19] RNN F score: 96.64%, Acc.: 99.64%,Sen.: 96.60, Spe.: 99.15%[20] CNN,RNN F score: 83.5%ThisworkCNN Acc:97% , Pre:97% , Re95%, Fscore: 96%V. CONCLU
